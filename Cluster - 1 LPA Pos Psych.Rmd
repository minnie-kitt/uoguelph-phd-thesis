---
title: "R Notebook"
output: html_notebook
---

# Set up

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

```{r}
source("Functions/dg_lpa_functions.R", local = knitr::knit_global())
```

# Load packages
```{r include=FALSE}
library(dplyr)
library(tidyverse)
library(reshape2)
library(tidyLPA)
library(ggplot2)
library(tibble)
library(mclust)
```

# Load individual questions data
```{r "import data"}
df_indiv <- read.csv("~/Desktop/Quant/Analysis/Output/individual_cleaned_scores.csv", header = TRUE, row.names = "X")
```

Only include `Resilience, PWB, ProQOL, Burnout`
```{r}
df_indiv <- df_indiv[c(1:55,107:116)]
```

# New score locations
```{r}
cdr <- c(4:13)
pwb <- c(14:55)
proqol <- c(56:64)
burnout <- 65

p_autonomy <- pwb[c(1,7,13,19,25,31,37)]
p_envi_master <- pwb[c(2,8,14,20,26,32,38)]
p_pers_growth <- pwb[c(3,9,15,21,27,33,39)]
p_pos_relation <- pwb[c(4,10,16,22,28,34,40)]
p_purpose <- pwb[c(5,11,17,23,29,35,41)]
p_self_acc <- pwb[c(6,12,18,24,30,36,42)]
  
pq_cf <- proqol[c(1,4,7)]
pq_bo <- proqol[c(2,6,8)]
pq_cs <- proqol[c(3,5,9)]
  

all_scales <- list(Resilience=cdr,Burnout=burnout,
#                p_autonomy=p_autonomy,p_envi_master=p_envi_master,
#                p_pers_growth=p_pers_growth,p_pos_relation=p_pos_relation,
#                p_purpose=p_purpose,p_self_acc=p_self_acc, ## PWB
                PWB = pwb,
                CB=pq_bo,STS=pq_cf,CS=pq_cs ## ProQOL
                )
```


## Create `baseline` and remove missing data
```{r}
baseline <- df_indiv[df_indiv$metadata.count==1,]
rm(df_indiv)
df_rm_na <- na.omit(baseline)
rm(baseline)
rownames(df_rm_na) <- NULL
```

## Scale the data
```{r}
scaled_df <- data.frame(scale(df_rm_na[,c(4:65)]))
```

# Models
## Model 1
```{r include=FALSE}
set.seed(1995)
BIC<-mclustBIC(scaled_df)
model1 <- c(1,names(summary(BIC)[1]), summary(BIC)[[1]]-summary(BIC)[[1]],
            names(summary(BIC)[2]), summary(BIC)[[1]]-summary(BIC)[[2]],
            names(summary(BIC)[3]), summary(BIC)[[1]]-summary(BIC)[[3]])
```

### Check 400 iterations
```{r eval=FALSE, include=FALSE}
for(iteration in 1:399){
  BIC<-mclustBIC(scaled_df)
  print(summary(BIC))
  temp <- c(iteration+1,
            names(summary(BIC)[1]), summary(BIC)[[1]]-summary(BIC)[[1]],
            names(summary(BIC)[2]), summary(BIC)[[1]]-summary(BIC)[[2]],
            names(summary(BIC)[3]), summary(BIC)[[1]]-summary(BIC)[[3]])
  model1 <- rbind(model1,temp)
}
model1 <- as.data.frame(model1)

colnames(model1) <- c("Iteration", "M1_Name","M1_Value",
                      "M2_Name","M2_Value","M3_Name","M3_Value")
model1$Iteration <- as.numeric(model1$Iteration)
row.names(model1) <- NULL
write.csv(model1,"Output/pp-clusters-model1-iterations.csv")
```
```{r}
model1 <- read.csv("Output/pp-clusters-model1-iterations.csv", row.names = "X")
table(model1[2])
table(model1[4])
plot(model1$M2_Value, type = "l")
table(model1[6])
plot(model1$M3_Value, type = "l")
```

```{r}
plot(BIC, legendArgs = list(x = "bottomright", ncol = 5))
```
```{r}
summary(BIC)
```


```{r}
lpa.results<-LPA(scaled_df, "EII", 5, BIC)
summary(lpa.results)
```
```{r}
summary(LPA(scaled_df, "EEI", 5, BIC))
```
```{r}
summary(LPA(scaled_df, "EII", 4, BIC))
```


```{r}
calculateQuestionMeansScaled(lpa.results)
```

```{r}
df_rm_na$class1 <- lpa.results$classification
df_rm_na[df_rm_na$class1==4,]; df_rm_na[df_rm_na$class1==5,]
```

### Remove "outliers"
```{r}
df2 <- df_rm_na[-c(96,163),]
df2[df2$metadata.ID==51765,]; df2[df2$metadata.ID==64223,]
```

## Model 2: Re-run LPA (All scales) with outliers from Model 1 removed
```{r}
scaled_df2 <- data.frame(scale(df2[,c(4:65)]))
```

```{r include=FALSE}
BIC<-mclustBIC(scaled_df2)
```
### Check 400 iterations
```{r eval=FALSE, include=FALSE}
model2 <- c(1,
            names(summary(BIC)[1]), summary(BIC)[[1]]-summary(BIC)[[1]],
            names(summary(BIC)[2]), summary(BIC)[[1]]-summary(BIC)[[2]],
            names(summary(BIC)[3]), summary(BIC)[[1]]-summary(BIC)[[3]])
for(iteration in 1:399){
  BIC<-mclustBIC(scaled_df2)
  temp <- c(iteration+1,
            names(summary(BIC)[1]), summary(BIC)[[1]]-summary(BIC)[[1]],
            names(summary(BIC)[2]), summary(BIC)[[1]]-summary(BIC)[[2]],
            names(summary(BIC)[3]), summary(BIC)[[1]]-summary(BIC)[[3]])
  model2 <- rbind(model2,temp)
}
model2 <- as.data.frame(model2)

colnames(model2)  <- c("Iteration", "M1_Name","M1_Value",
                      "M2_Name","M2_Value","M3_Name","M3_Value")
model2$Iteration <- as.numeric(model2$Iteration)
row.names(model2) <- NULL
write.csv(model2,"Output/pp-clusters-model2-iterations.csv")
```
```{r}
model2 <- read.csv("Output/pp-clusters-model2-iterations.csv", row.names = "X")

table(model2[2])
plot(model2$M2_Value, type = "l")
table(model2[4])
plot(model2$M3_Value, type = "l")
table(model2[6])
```

```{r}
plot(BIC, legendArgs = list(x = "bottomright", ncol = 5))
summary(BIC)
```
```{r}
lpa.results<-LPA(scaled_df2, "EII", 2, BIC)
summary(lpa.results)
```
```{r}
summary(LPA(scaled_df2, "EEI", 4, BIC))
```
```{r}
summary(LPA(scaled_df2, "EII", 5, BIC))
```


```{r}
df2$class2 <- lpa.results$classification
scaled_df2 <- df2
scaled_df2[,c(4:65)] <- data.frame(scale(df2[,c(4:65)]))
```

# Compare the classifications given by each model

## Combine the dataframe
```{r}
df_results <- merge(df_rm_na,df2,all.x = TRUE)
df_results[is.na(df_results)] <- 0
```

```{r}
scaled_df_results <- df_results
scaled_df_results[,c(4:65)] <- scale(df_results[,c(4:65)])
```

# Look at Model 1 Classification
```{r}
table(df_results$class1)
```
## Compare Models 1 & 2
```{r}
table(df_results$class1,df_results$class2)
```

```{r}
results_df2_scaled <- summarizeDimensionMeansScaled(scaled_df2,"class2",dimension = "all", calculate_ci = TRUE)
```

```{r}

results_all_scaled <- summarizeDimensionMeansScaled(scaled_df_results,"class2",dimension = "all", calculate_ci = TRUE)
```

```{r}
ggplot(data=results_df2_scaled, 
       aes(x=factor(Dimension, levels = c("Resilience","PWB","CS","CB","STS","Burnout")),
           y=Mean, group=as.factor(Group), color=as.factor(Group))) +
    geom_line() +
    geom_line(linetype="dashed",
              aes(x=Dimension, y=CILow), 
              inherit.aes=TRUE) +
    geom_line(linetype="dashed",
              aes(x=Dimension, y=CIHigh, group=as.factor(Group), color=as.factor(Group)), 
              inherit.aes=TRUE) +
    scale_y_continuous(limits=c(-.8, .9)) +
  labs(title="Plot of Mean (Scaled) Scores Psychological Outcomes by Group",
       x=element_blank(), y = element_blank())+
  theme(legend.title = element_blank(),
        legend.position = c(0.06, 0.88),
        legend.background = element_rect(fill = "white"))+
  scale_color_brewer(palette = "Set2")
```
```{r}
calculateQuestionMeansScaled(lpa.results)
```
```{r}
cdrisc_u <- calculateQuestionMeansUnscaled(df2[cdr],classifications = df2$class2)
```
```{r}
pq_cs_u <- calculateQuestionMeansUnscaled(df2[pq_cs],classifications = df2$class2)
```

```{r}
pq_cf_u <- calculateQuestionMeansUnscaled(df2[pq_cf],classifications = df2$class2)
```
```{r}
pq_bo_u <- calculateQuestionMeansUnscaled(df2[pq_bo],classifications = df2$class2)
```
```{r}
p_self_acc_u <- calculateQuestionMeansUnscaled(df2[p_self_acc],classifications = df2$class2)
```
```{r}
p_envi_master_u <- calculateQuestionMeansUnscaled(df2[p_envi_master],classifications = df2$class2)
```


```{r}
p_autonomy_u <- calculateQuestionMeansUnscaled(df2[p_autonomy],classifications = df2$class2)
```


```{r}
p_pers_growth_u <- calculateQuestionMeansUnscaled(df2[p_pers_growth],classifications = df2$class2)
```


```{r}
p_purpose_u <- calculateQuestionMeansUnscaled(df2[p_purpose],classifications = df2$class2)
```


```{r}
p_pos_relation_u <- calculateQuestionMeansUnscaled(df2[p_pos_relation],classifications = df2$class2)
```
# Format Results

```{r}
format_results <- function(results_df,measurement = "Dimension", with_ci = TRUE){
  if(with_ci==TRUE){
    out <- data.frame(cbind(results_df[measurement],results_df["Group"],results_df["Mean"]))
    colnames(out) <- c(measurement, "Group","Mean (95%CI)")
    all_measurement <- unique(results_df[[measurement]])
    all_group <- unique(results_df[["Group"]])
    for(group in all_group){
      for(measure in all_measurement){
        temp_row <- results_df[results_df[[measurement]]==measure & results_df[["Group"]]==group,]
        row_num <- row.names(results_df[results_df[[measurement]]==measure & results_df[["Group"]]==group,])
        group_mean <- round(temp_row[["Mean"]],2)
        group_CILow <- round(temp_row[["CILow"]],2)
        group_CIHigh <- round(temp_row[["CIHigh"]],2)
        output <- paste0(group_mean," (95%CI ",group_CILow," - ",group_CIHigh,")")
        out[row_num,3] <- output
      }}}
  return(out)
  }
```


```{r}

temp <- df2
temp[cdr]<- temp[cdr]*10
temp[proqol] <- temp[proqol]*3
temp[pwb] <- temp[pwb]
results_all <- summarizeDimensionMeansScaled(temp,"class2",dimension = "all", calculate_ci = TRUE)
```


```{r}
format_results(results_all[results_all$Group==1,])
```
```{r}
format_results(results_all[results_all$Group==2,])
```



# Descriptive Stats
```{r}
temp_df_demo <- read.csv("~/Desktop/Quant/Analysis/Output/all_scores_demographic.csv", header = TRUE, row.names = "X")

df_demo <- merge(df_results, temp_df_demo, by.x = c("metadata.ID","metadata.class","metadata.count"), by.y = c("ID","class","time"))[c(1:3,66,67,68,72:78,86:88,91,92:112)]

colnames(df_demo)[1:5] <- c("ID","class","time","lpa1","lpa2")
```

```{r}
demo_high<- df_demo[df_demo$lpa2==1,]
```
```{r}
demo_low <- df_demo[df_demo$lpa2==2,]
```

```{r include=FALSE}
cat_freq <- function(data=df_demo,var){
  x <- na.omit(data[[var]])
  xtab <- table(x)
  lev <- unique(x)
  
  out <- data.frame()
  prop <- prop.table(xtab)
  for(i in 1:length(lev)){
    new_row <- data.frame(
      Count = xtab[i],
      Percentage = round(100*prop[i],1))
    out <- rbind(out,new_row)
  }
  # Print the table
  print(paste("Total n = ",length(na.omit(data[[var]]))))
  print(paste("Total missing = ", sum(is.na(data[[var]]))))
  print(out)
}
```
## Class
```{r}
cat_freq(df_demo,"class")
```

```{r}
cat_freq(demo_low,"class")
```
```{r}
cat_freq(demo_high,"class")
```
## School

```{r}
cat_freq(df_demo,"school")
```


```{r}
cat_freq(demo_low,"school")
```
```{r}
cat_freq(demo_high,"school")
```
## Gender
```{r}
cat_freq(df_demo,"gender")
```
```{r}
cat_freq(demo_low,"gender")
```
```{r}
cat_freq(demo_high,"gender")
```
## Ethnicity
```{r}
cat_freq(df_demo,"ethnicity")
```
```{r}
cat_freq(demo_low,"ethnicity")
```
```{r}
cat_freq(demo_high,"ethnicity")
```
## Career
```{r}
cat_freq(df_demo,"career")
```
```{r}
cat_freq(demo_low,"career")
```
```{r}
cat_freq(demo_high,"career")
```



## Age
```{r}
cat_freq(demo_low,"age_cat")
```
```{r}
cat_freq(demo_high,"age_cat")
```

## Disability
```{r}
cat_freq(demo_low,"disab_simple")
```
```{r}
cat_freq(demo_high,"disab_simple")
```
## MH Hx
```{r}
cat_freq(demo_low,"mh_diag")
```
```{r}
cat_freq(demo_high,"mh_diag")
```
## MH Treatment
```{r}
cat_freq(demo_low,"mh_tx")
```
```{r}
cat_freq(demo_high,"mh_tx")
```
# Scores
```{r}
score_summary <- function(variable = "cdrisc", data = df_demo){
  print(paste("n =",NROW(data[[variable]])))
  print(round(summary(data[[variable]]),2))
  print(paste("SD =", round(sd(data[[variable]]),2)))
}
```

```{r}
NROW(na.omit(df_demo$age))
summary(na.omit(df_demo$age))
round(sd(na.omit(df_demo$age)),2)
```

```{r}
score_summary("cdrisc")
```
```{r}
score_summary("cdrisc", demo_low)
```
```{r}
score_summary("cdrisc", demo_high)
```
```{r}
temp_df_demo <- rbind(demo_high, demo_low)
shapiro.test(temp_df_demo$cdrisc)
t.test(cdrisc ~ lpa2, data = temp_df_demo)
```

```{r}
df_demo$pwb <- df_demo$pwb/42
demo_low$pwb <- demo_low$pwb/42
demo_high$pwb <- demo_high$pwb/42
```

```{r}
score_summary("pwb")
```
```{r}
score_summary("pwb", demo_low)
```
```{r}
score_summary("pwb", demo_high)
```

```{r}
shapiro.test(temp_df_demo$pwb)
wilcox.test(pwb ~ lpa2, data = temp_df_demo)
```

```{r}
score_summary("pq_cs")
```
```{r}
score_summary("pq_cs", demo_low)
```
```{r}
score_summary("pq_cs", demo_high)
```
```{r}
shapiro.test(temp_df_demo$pq_cs)
wilcox.test(pq_cs ~ lpa2, data = temp_df_demo)
```
```{r}
score_summary("pq_bo")
```
```{r}
score_summary("pq_bo", demo_low)
```
```{r}
score_summary("pq_bo", demo_high)
```
```{r}
shapiro.test(temp_df_demo$pq_bo)
wilcox.test(pq_bo ~ lpa2, data = temp_df_demo)
```
```{r}
score_summary("pq_cf")
```
```{r}
score_summary("pq_cf", demo_low)
```

```{r}
score_summary("pq_cf", demo_high)
```
```{r}
shapiro.test(temp_df_demo$pq_cf)
wilcox.test(pq_cf ~ lpa2, data = temp_df_demo)
```

```{r}
score_summary("burnout")
```
```{r}
table(df_demo$burnout)
```

```{r}
round(prop.table(table(df_demo$burnout))*100,1)
```
```{r}
df_demo$burnout_0 <- ifelse(df_demo$burnout>3,2,df_demo$burnout)
df_demo$burnout_0 <- ifelse(df_demo$burnout==3,1,df_demo$burnout_0)
df_demo$burnout_0 <- ifelse(df_demo$burnout<3,0,df_demo$burnout_0)
table(df_demo$burnout_0)
round(prop.table(table(df_demo$burnout_0))*100,1)
```

```{r}
score_summary("burnout", demo_low)
```
```{r}
table(demo_low$burnout)
round(prop.table(table(demo_low$burnout))*100,1)
```
```{r}
demo_low$burnout_0 <- ifelse(demo_low$burnout>3,2,demo_low$burnout)
demo_low$burnout_0 <- ifelse(demo_low$burnout==3,1,demo_low$burnout_0)
demo_low$burnout_0 <- ifelse(demo_low$burnout<3,0,demo_low$burnout_0)
table(demo_low$burnout_0)
round(prop.table(table(demo_low$burnout_0))*100,1)
```
```{r}
score_summary("burnout", demo_high)
```
```{r}
round(prop.table(table(demo_high$burnout))*100,1)
```

```{r}
demo_high$burnout_0 <- ifelse(demo_high$burnout>3,2,demo_high$burnout)
demo_high$burnout_0 <- ifelse(demo_high$burnout==3,1,demo_high$burnout_0)
demo_high$burnout_0 <- ifelse(demo_high$burnout<3,0,demo_high$burnout_0)
table(demo_high$burnout_0)
round(prop.table(table(demo_high$burnout_0))*100,1)
```


```{r}
fisher.test(table(temp_df_demo$lpa2,temp_df_demo$burnout))
```

```{r eval=FALSE, include=FALSE}
library(GGally)

ggparcoord(data = iris,
           columns = 1:4,
           groupColumn = "Species") +
           scale_color_brewer(palette = "Set2") 

scaled_df_results$class2 <- as.factor(scaled_df_results$class2)
scaled_df_results$metadata.ID <- as.factor(scaled_df_results$metadata.ID)

```

```{r}
df_demo[df_demo$lpa2==0,c(6,13,16,15,14,17)]
```

```{r}
colnames(df_demo)[c(6,13,16,15,14,17)] <- c("Resilience", "PWB","CS","CB","STS","Burnout")
df_demo$lpa1 <- as.factor(df_demo$lpa1)
```


```{r}
library(GGally)
ggparcoord(data = df_demo,
           columns = c(6,13,16,15,14,17),
           groupColumn = "lpa1",
           scale = "std",
           showPoints = TRUE) +
           scale_color_brewer(palette = "Set2") +
             facet_wrap(~ lpa1)
```


# Dumbbell plot

```{r}

temp_results_all_scaled <- results_all_scaled[results_all_scaled$Group>0,]
temp_results_all_scaled$Group <- as.factor(temp_results_all_scaled$Group)

ggplot(temp_results_all_scaled, aes(x = Mean, y = Dimension)) +
  geom_line() +
  geom_point(aes(color = Group), size = 3) +
  scale_color_brewer(palette = "Set2") +
  theme(legend.position = "bottom") 

```


```{r eval=FALSE, include=FALSE}
ggparcoord(data = temp_df_demo,
           columns = 6:16,
           groupColumn = "lpa2",
           scale = "center",
           alphaLines = 0.2,
           showPoints = TRUE,
           boxplot = TRUE) +
           scale_color_brewer(palette = "Set2") +
  facet_wrap(~ lpa2)
```

## End
```{r eval=FALSE, include=FALSE}
df_results$gr_lpa <- df_results$class2
write.csv(df_results[c(1:65,68)], "Output/baseline_individual_pp_lpa_cluster.csv")
```

```{r "write `new baseline`", eval=FALSE, include=FALSE}
baseline <- read.csv("Output/baseline-for-modelling.csv", header = TRUE, row.names = "X")
newdata <- df_results[,c("metadata.ID","metadata.class","metadata.count","class2")]
new_baseline <- merge(newdata,baseline,by.y= c("ID","class","time"), 
                    by.x = c("metadata.ID","metadata.class","metadata.count"),
                    all = FALSE,
                    no.dups = TRUE
                    )
colnames(new_baseline)[1:4] <- c("ID","class","time","gr_lpa")
write.csv(new_baseline,file= "Output/baseline_for_modelling_with_lpa_clust.csv")
```



